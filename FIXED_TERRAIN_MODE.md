# 固定地形模式 - 关键改进

## 问题：随机地形的挑战

在BipedalWalker-v3环境中，每次`reset()`都会生成**随机地形**：
- 不同的坡度
- 不同的障碍物位置
- 不同的间隙宽度

这导致：
1. ❌ **评估不稳定** - 同一个策略在不同地形上表现差异巨大
2. ❌ **选择不准确** - 可能因为运气好淘汰了真正优秀的个体
3. ❌ **需要多次评估** - 为了减少随机性必须多次运行取平均
4. ❌ **训练速度慢** - 多次评估大幅增加计算量

## 解决方案：固定地形模式

### 核心思想
**所有个体在相同的地形上竞争**
- 使用固定的seed列表：`[42, 123, 456, 789, 1024]`
- 每个个体在这5个固定地形上运行
- 取平均fitness作为评估结果

### 优势

#### 1. 评估准确 ✅
```python
# 之前（随机）：个体A运气好遇到简单地形
Individual A: terrain_seed=random() → easy terrain → high fitness ❌

# 现在（固定）：所有个体都在相同地形上比较
Individual A: terrains=[42,123,456,789,1024] → fair comparison ✅
Individual B: terrains=[42,123,456,789,1024] → fair comparison ✅
```

#### 2. 训练稳定 ✅
- 每代的fitness可比较（地形相同）
- 训练曲线平滑上升
- NEW RECORD真实反映进步

#### 3. 速度快 ✅
```
之前（随机+多次评估）：
200个体 × 2次评估 = 400次环境运行/代

现在（固定+单次）：
200个体 × 5个地形 = 1000次环境运行/代

但！固定地形意味着不需要多次试错，实际上会更快收敛
```

#### 4. 视频一致 ✅
- 所有NEW RECORD视频都在同一地形(seed=42)上
- 可以直接对比不同代数的进步

### 实现细节

```python
# config.py
USE_FIXED_TERRAIN = True
TERRAIN_SEEDS = [42, 123, 456, 789, 1024]  # 5个固定地形
EVAL_EPISODES = 1  # 不需要多次了
```

```python
# train_with_video.py
def evaluate_individual(params, network, env, max_steps, terrain_seeds):
    rewards = []
    for seed in terrain_seeds:
        env.reset(seed=seed)  # 固定地形
        # ... 运行并记录reward
    return np.mean(rewards)  # 5个地形的平均表现
```

### 地形选择策略

选择了5个不同难度的地形：
- `seed=42`: 中等难度
- `seed=123`: 简单地形
- `seed=456`: 困难地形
- `seed=789`: 中等偏难
- `seed=1024`: 中等偏简单

**平均后** → 评估模型的**泛化能力**

### 与随机地形对比

| 特性 | 随机地形 | 固定地形 |
|------|---------|----------|
| 评估公平性 | ❌ 差 | ✅ 好 |
| 训练稳定性 | ❌ 波动大 | ✅ 平滑 |
| 需要多次评估 | ✅ 需要 | ❌ 不需要 |
| 视频可比性 | ❌ 差 | ✅ 好 |
| 泛化能力测试 | ✅ 好 | ⚠️ 需要多个固定地形 |
| 训练速度 | ⚠️ 慢 | ✅ 快 |

## 预期效果

### Round 5 (随机地形) vs Round 6 (固定地形)

| 指标 | Round 5 | Round 6 预期 |
|------|---------|--------------|
| 每代时间 | ~20秒 | **~30秒** (5个地形) |
| Fitness稳定性 | 中等 | **高** |
| 训练曲线 | 波动 | **平滑上升** |
| 最终效果 | ? | **更好** |
| 视频质量 | 一致 | **完全一致** |

### 为什么可能更好？

1. **更准确的选择压力** - 不会误淘汰优秀基因
2. **更稳定的进化方向** - 每代都朝着真正的优化方向前进
3. **更少的运气成分** - 完全依靠策略质量

## 开关控制

如果想回到随机地形模式：
```python
# config.py
USE_FIXED_TERRAIN = False  # 关闭固定地形
```

## 总结

**固定地形模式 = 更公平 + 更稳定 + 更快收敛**

这是针对Round 5训练中观察到的"停滞"问题的另一个解决方案：
- Round 5的停滞可能部分由于评估的随机性
- 固定地形后，每次突破都是真实的进步

