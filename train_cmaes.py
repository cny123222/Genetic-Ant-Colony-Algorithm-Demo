"""
CMA-ESè®­ç»ƒè„šæœ¬
ä½¿ç”¨åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥
æ¯”æ ‡å‡†GAåœ¨é«˜ç»´ç©ºé—´æ›´é«˜æ•ˆ
"""

import numpy as np
import gymnasium as gym
import cma
import os
import time
from datetime import datetime
from neural_network import NeuralNetwork, save_network, create_random_params
import config


def evaluate_individual(network, env_name, max_steps, seed=None):
    """è¯„ä¼°å•ä¸ªä¸ªä½“çš„é€‚åº”åº¦"""
    env = gym.make(env_name)
    
    if seed is not None:
        observation, _ = env.reset(seed=seed)
    else:
        observation, _ = env.reset()
    
    total_reward = 0
    steps = 0
    
    for _ in range(max_steps):
        action = network.predict(observation)
        observation, reward, terminated, truncated, _ = env.step(action)
        total_reward += reward
        steps += 1
        
        if terminated or truncated:
            break
    
    env.close()
    return total_reward


def save_video_of_best(params, network, env_name, generation, max_steps):
    """ä¿å­˜æœ€ä½³ä¸ªä½“çš„è§†é¢‘"""
    from gymnasium.wrappers import RecordVideo
    
    # è®¾ç½®å‚æ•°
    network.set_params(params)
    
    # åˆ›å»ºè§†é¢‘ä¿å­˜ç›®å½•
    video_folder = f"videos_cmaes/gen_{generation:03d}"
    os.makedirs(video_folder, exist_ok=True)
    
    # åˆ›å»ºç¯å¢ƒå¹¶å½•åˆ¶
    env = gym.make(env_name, render_mode="rgb_array")
    env = RecordVideo(
        env, 
        video_folder,
        name_prefix=f"best_gen{generation}",
        episode_trigger=lambda x: True
    )
    
    observation, _ = env.reset(seed=config.RANDOM_SEED if config.RANDOM_SEED else None)
    total_reward = 0
    
    for _ in range(max_steps):
        action = network.predict(observation)
        observation, reward, terminated, truncated, _ = env.step(action)
        total_reward += reward
        
        if terminated or truncated:
            break
    
    env.close()
    return total_reward


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®éšæœºç§å­
    if config.RANDOM_SEED is not None:
        np.random.seed(config.RANDOM_SEED)
    
    # åˆ›å»ºç¯å¢ƒä»¥è·å–ç»´åº¦
    env = gym.make(config.ENV_NAME)
    input_size = env.observation_space.shape[0]
    output_size = env.action_space.shape[0]
    env.close()
    
    # åˆ›å»ºç¥ç»ç½‘ç»œ
    network = NeuralNetwork(input_size, config.HIDDEN_LAYERS, output_size)
    param_count = network.param_count
    
    print("=" * 80)
    print("CMA-ESè®­ç»ƒå¼€å§‹")
    print("=" * 80)
    print(f"ç¯å¢ƒ: {config.ENV_NAME}")
    print(f"ç½‘ç»œç»“æ„: {input_size} â†’ {' â†’ '.join(map(str, config.HIDDEN_LAYERS))} â†’ {output_size}")
    print(f"å‚æ•°æ€»æ•°: {param_count:,}")
    print(f"ç§ç¾¤å¤§å°: ç”±CMA-ESè‡ªåŠ¨ç¡®å®šï¼ˆé»˜è®¤ 4 + 3*ln(N) â‰ˆ {4 + int(3 * np.log(param_count))}ï¼‰")
    print(f"æœ€å¤§è¿­ä»£æ•°: {config.GENERATIONS}")
    print(f"éšæœºç§å­: {config.RANDOM_SEED}")
    print("=" * 80)
    print()
    
    # åˆå§‹åŒ–CMA-ES
    initial_params = create_random_params(param_count, scale=0.1)
    sigma0 = 0.5  # åˆå§‹æ­¥é•¿
    
    # CMA-ESé€‰é¡¹
    cma_options = {
        'maxiter': config.GENERATIONS,
        'popsize': 100,  # å›ºå®šç§ç¾¤å¤§å°ä¸º100ï¼Œä¸ä¹‹å‰GAä¿æŒä¸€è‡´
        'verb_disp': 1,  # æ¯ä»£æ˜¾ç¤ºä¿¡æ¯
        'verb_log': 0,   # ä¸ä¿å­˜æ—¥å¿—æ–‡ä»¶
        'seed': config.RANDOM_SEED if config.RANDOM_SEED else None
    }
    
    es = cma.CMAEvolutionStrategy(initial_params, sigma0, cma_options)
    
    # è®­ç»ƒç»Ÿè®¡
    best_ever_fitness = float('-inf')
    best_ever_params = None
    training_start = time.time()
    
    print(f"è®­ç»ƒå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    try:
        iteration = 0
        while not es.stop():
            iteration += 1
            gen_start = time.time()
            
            # ç”Ÿæˆå€™é€‰è§£
            solutions = es.ask()
            
            # è¯„ä¼°æ‰€æœ‰å€™é€‰è§£
            fitness_scores = []
            for i, params in enumerate(solutions):
                network.set_params(params)
                fitness = evaluate_individual(
                    network, 
                    config.ENV_NAME, 
                    config.MAX_STEPS,
                    seed=config.RANDOM_SEED if config.RANDOM_SEED else None
                )
                fitness_scores.append(fitness)
                
                if config.SHOW_PROGRESS and (i + 1) % 10 == 0:
                    print(f"Eval: {i+1}/{len(solutions)}...", end=" ", flush=True)
            
            if config.SHOW_PROGRESS:
                print()  # æ¢è¡Œ
            
            # å‘Šè¯‰CMA-ESè¯„ä¼°ç»“æœï¼ˆæ³¨æ„ï¼šCMA-ESæœ€å°åŒ–ï¼Œæ‰€ä»¥å–è´Ÿå€¼ï¼‰
            es.tell(solutions, [-f for f in fitness_scores])
            
            # ç»Ÿè®¡ä¿¡æ¯
            best_fitness = max(fitness_scores)
            best_idx = np.argmax(fitness_scores)
            best_params = solutions[best_idx]
            mean_fitness = np.mean(fitness_scores)
            std_fitness = np.std(fitness_scores)
            
            # æ›´æ–°å…¨å±€æœ€ä¼˜
            new_record = False
            if best_fitness > best_ever_fitness:
                best_ever_fitness = best_fitness
                best_ever_params = best_params.copy()
                new_record = True
            
            # æ˜¾ç¤ºè¿›åº¦
            gen_time = time.time() - gen_start
            if new_record:
                print(f"[Gen {iteration}/{config.GENERATIONS}] â­ NEW RECORD! Best: {best_fitness:.2f}, Mean: {mean_fitness:.2f}, Std: {std_fitness:.2f} | Time: {gen_time:.1f}s")
                
                # ä¿å­˜è§†é¢‘
                if best_ever_params is not None:
                    print("Recording video...", end=" ", flush=True)
                    video_reward = save_video_of_best(
                        best_ever_params,
                        network,
                        config.ENV_NAME,
                        iteration,
                        config.MAX_STEPS
                    )
                    print(f"OK (reward: {video_reward:.1f})")
            else:
                print(f"[Gen {iteration}/{config.GENERATIONS}] Best: {best_fitness:.2f}, Mean: {mean_fitness:.2f}, Std: {std_fitness:.2f} | Time: {gen_time:.1f}s")
            
            # å®šæœŸä¿å­˜æ¨¡å‹
            if iteration % config.SAVE_FREQUENCY == 0 and best_ever_params is not None:
                checkpoint_path = f"models_cmaes/best_model_gen{iteration}.npy"
                os.makedirs("models_cmaes", exist_ok=True)
                network.set_params(best_ever_params)
                save_network(network, checkpoint_path)
                print(f"ğŸ’¾ Checkpoint saved: {checkpoint_path}")
            
            print()
    
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    
    # è®­ç»ƒç»“æŸ
    training_time = time.time() - training_start
    
    print("\n" + "=" * 80)
    print("è®­ç»ƒå®Œæˆ")
    print("=" * 80)
    print(f"æ€»ç”¨æ—¶: {training_time/3600:.2f} å°æ—¶ ({training_time/60:.1f} åˆ†é’Ÿ)")
    print(f"æœ€ç»ˆæœ€ä½³é€‚åº”åº¦: {best_ever_fitness:.2f}")
    print(f"å¹³å‡æ¯ä»£ç”¨æ—¶: {training_time/iteration:.1f} ç§’")
    print("=" * 80)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    if best_ever_params is not None:
        network.set_params(best_ever_params)
        final_model_path = "best_model_cmaes.npy"
        save_network(network, final_model_path)
        print(f"\nâœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
        
        # ä¿å­˜æœ€ç»ˆè§†é¢‘
        print("\nå½•åˆ¶æœ€ç»ˆæ¼”ç¤ºè§†é¢‘...", end=" ", flush=True)
        final_reward = save_video_of_best(
            best_ever_params,
            network,
            config.ENV_NAME,
            iteration,
            config.MAX_STEPS
        )
        print(f"å®Œæˆï¼(reward: {final_reward:.1f})")
    
    print("\nğŸ‰ CMA-ESè®­ç»ƒå…¨éƒ¨å®Œæˆï¼")


if __name__ == "__main__":
    main()

