"""
è®­ç»ƒç¨‹åºï¼ˆå¸¦è§†é¢‘å½•åˆ¶åŠŸèƒ½ï¼‰
å®šæœŸä¿å­˜æœ€ä¼˜ä¸ªä½“çš„æ¼”ç¤ºè§†é¢‘ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸åŒä»£æ•°çš„è®­ç»ƒæ•ˆæœ
"""

import gymnasium as gym
import numpy as np
import time
import os
import sys
from datetime import datetime
from neural_network import NeuralNetwork, save_network
from genetic_algorithm import GeneticAlgorithm, AdaptiveGeneticAlgorithm
import config


def evaluate_individual(params, network, env, max_steps):
    """è¯„ä¼°å•ä¸ªä¸ªä½“çš„é€‚åº”åº¦"""
    network.set_params(params)
    observation, info = env.reset()
    total_reward = 0.0
    
    for step in range(max_steps):
        action = network.predict(observation)
        observation, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        
        if terminated or truncated:
            break
    
    return total_reward


def save_video_of_best(params, network, env_name, generation, max_steps, video_dir="videos", num_trials=3):
    """
    ä¿å­˜æœ€ä¼˜ä¸ªä½“çš„è§†é¢‘ï¼ˆå½•åˆ¶å¤šæ¬¡ï¼Œä¿å­˜æœ€å¥½çš„ä¸€æ¬¡ï¼‰
    
    Args:
        params: ç¥ç»ç½‘ç»œå‚æ•°
        network: ç¥ç»ç½‘ç»œå®ä¾‹
        env_name: ç¯å¢ƒåç§°
        generation: å½“å‰ä»£æ•°
        max_steps: æœ€å¤§æ­¥æ•°
        video_dir: è§†é¢‘ä¿å­˜ç›®å½•
        num_trials: å°è¯•æ¬¡æ•°ï¼ˆå–æœ€å¥½çš„ï¼‰
    """
    # åˆ›å»ºè§†é¢‘ç›®å½•
    os.makedirs(video_dir, exist_ok=True)
    
    network.set_params(params)
    
    # å…ˆè¿è¡Œå¤šæ¬¡æ‰¾åˆ°æœ€å¥½çš„seed
    best_reward = -np.inf
    best_seed = 0
    
    for trial in range(num_trials):
        env_test = gym.make(env_name)
        observation, info = env_test.reset(seed=trial)
        trial_reward = 0.0
        
        for step in range(max_steps):
            action = network.predict(observation)
            observation, reward, terminated, truncated, info = env_test.step(action)
            trial_reward += reward
            if terminated or truncated:
                break
        
        env_test.close()
        
        if trial_reward > best_reward:
            best_reward = trial_reward
            best_seed = trial
    
    # ä½¿ç”¨æœ€å¥½çš„seedå½•åˆ¶è§†é¢‘
    try:
        video_path = os.path.join(video_dir, f"gen_{generation:03d}")
        env = gym.make(env_name, render_mode='rgb_array')
        env = gym.wrappers.RecordVideo(
            env, 
            video_path,
            episode_trigger=lambda x: True,
            name_prefix=f"best_gen{generation}"
        )
        
        observation, info = env.reset(seed=best_seed)
        total_reward = 0.0
        steps = 0
        
        for step in range(max_steps):
            action = network.predict(observation)
            observation, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            steps += 1
            
            if terminated or truncated:
                break
        
        env.close()
        
        print(f"OK (best of {num_trials} trials, reward: {total_reward:.1f}, steps: {steps})", end=' ')
        sys.stdout.flush()
        return total_reward
        
    except Exception as e:
        print(f"Failed: {e}", end=' ')
        sys.stdout.flush()
        return 0.0


def main():
    """ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºé…ç½®
    config.print_config()
    
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è§†é¢‘ä¿å­˜é¢‘ç‡: æ¯ {config.VIDEO_FREQUENCY} ä»£\n")
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    print("åˆå§‹åŒ–ç¯å¢ƒ...")
    try:
        env_test = gym.make(config.ENV_NAME)
        env_name = config.ENV_NAME
        print(f"âœ“ æˆåŠŸåŠ è½½ {env_name}")
    except Exception as e:
        print(f"âœ— æ— æ³•åŠ è½½ {config.ENV_NAME}: {e}")
        print(f"å°è¯•å¤‡é€‰ç¯å¢ƒ {config.FALLBACK_ENV}...")
        try:
            env_test = gym.make(config.FALLBACK_ENV)
            env_name = config.FALLBACK_ENV
            print(f"âœ“ æˆåŠŸåŠ è½½ {env_name}")
        except Exception as e2:
            print(f"âœ— æ— æ³•åŠ è½½å¤‡é€‰ç¯å¢ƒ: {e2}")
            return
    
    obs_dim = env_test.observation_space.shape[0]
    act_dim = env_test.action_space.shape[0]
    env_test.close()
    
    print(f"è§‚å¯Ÿç©ºé—´: {obs_dim}ç»´, åŠ¨ä½œç©ºé—´: {act_dim}ç»´\n")
    
    # åˆ›å»ºç¥ç»ç½‘ç»œ
    network = NeuralNetwork(obs_dim, config.HIDDEN_LAYERS, act_dim)
    print(f"ç½‘ç»œå‚æ•°æ•°é‡: {network.get_param_count()}\n")
    
    # åˆ›å»ºæ ‡å‡†é—ä¼ ç®—æ³•ï¼ˆå›ºå®šå˜å¼‚ç‡ï¼ŒæŒç»­æ¢ç´¢ï¼‰
    ga = GeneticAlgorithm(
        population_size=config.POPULATION_SIZE,
        param_count=network.get_param_count(),
        mutation_rate=config.MUTATION_RATE,
        mutation_scale=config.MUTATION_SCALE,
        crossover_rate=config.CROSSOVER_RATE,
        elite_ratio=config.ELITE_RATIO,
        tournament_size=config.TOURNAMENT_SIZE
    )
    print(f"ä½¿ç”¨æ ‡å‡†é—ä¼ ç®—æ³•ï¼ˆå›ºå®šé«˜å˜å¼‚ç‡ï¼š{config.MUTATION_RATE}ï¼‰")
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒï¼ˆä¸æ¸²æŸ“ï¼Œé€Ÿåº¦å¿«ï¼‰
    env_train = gym.make(env_name)
    
    # è®­ç»ƒç»Ÿè®¡
    stats_history = {
        'generation': [],
        'best_fitness': [],
        'mean_fitness': [],
        'std_fitness': []
    }
    
    best_ever_fitness = -np.inf
    best_ever_params = None
    
    print("=" * 60)
    print("å¼€å§‹è®­ç»ƒï¼ˆæ— å®æ—¶æ¸²æŸ“ï¼Œé€Ÿåº¦æ›´å¿«ï¼‰")
    print("=" * 60 + "\n")
    
    start_time = time.time()
    
    for generation in range(config.GENERATIONS):
        gen_start = time.time()
        
        print(f"\n[Gen {generation + 1}/{config.GENERATIONS}]", end=' ')
        sys.stdout.flush()
        
        # è¯„ä¼°ç§ç¾¤
        fitness_scores = []
        for i, individual in enumerate(ga.population):
            fitness = evaluate_individual(individual, network, env_train, config.MAX_STEPS)
            fitness_scores.append(fitness)
            
            if config.SHOW_PROGRESS and (i + 1) % 10 == 0:
                print(f"Eval: {i + 1}/{config.POPULATION_SIZE}...", end=' ')
                sys.stdout.flush()
        
        ga.fitness_scores = np.array(fitness_scores)
        
        # ç»Ÿè®¡
        stats = ga.get_statistics()
        best_individual, best_fitness = ga.get_best_individual()
        
        if best_fitness > best_ever_fitness:
            best_ever_fitness = best_fitness
            best_ever_params = best_individual.copy()
            print(f"NEW RECORD! ", end='')
            sys.stdout.flush()
        
        # è®°å½•
        stats_history['generation'].append(generation + 1)
        stats_history['best_fitness'].append(stats['best'])
        stats_history['mean_fitness'].append(stats['mean'])
        stats_history['std_fitness'].append(stats['std'])
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"Best: {stats['best']:.2f}, Mean: {stats['mean']:.2f}, Std: {stats['std']:.2f}", end=' ')
        sys.stdout.flush()
        
        # å®šæœŸä¿å­˜è§†é¢‘ï¼ˆä½¿ç”¨å†å²æœ€ä½³ä¸ªä½“ï¼‰
        if ((generation + 1) % config.VIDEO_FREQUENCY == 0 or generation == 0) and best_ever_params is not None:
            print(f"| Recording video...", end=' ')
            sys.stdout.flush()
            save_video_of_best(
                best_ever_params,  # ä½¿ç”¨å†å²æœ€ä½³
                network, 
                env_name, 
                generation + 1, 
                config.MAX_STEPS
            )
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (generation + 1) % config.SAVE_FREQUENCY == 0:
            print(f"| Saving checkpoint...", end=' ')
            sys.stdout.flush()
            network.set_params(best_ever_params)
            save_network(network, f"{config.CHECKPOINT_PREFIX}{generation+1}.npy")
            np.save(config.STATS_PATH, stats_history)
            print(f"Done", end=' ')
            sys.stdout.flush()
        
        # è¿›åŒ–
        if generation < config.GENERATIONS - 1:
            ga.evolve()
        
        gen_time = time.time() - gen_start
        print(f"| Time: {gen_time:.1f}s")
        sys.stdout.flush()
    
    # å®Œæˆ
    total_time = time.time() - start_time
    print("=" * 60)
    print("è®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"æœ€ä½³é€‚åº”åº¦: {best_ever_fitness:.2f}\n")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    network.set_params(best_ever_params)
    save_network(network, config.BEST_MODEL_PATH)
    np.save(config.STATS_PATH, stats_history)
    
    # ä¿å­˜æœ€ç»ˆè§†é¢‘
    print("ğŸ“¹ å½•åˆ¶æœ€ç»ˆæœ€ä½³ä¸ªä½“è§†é¢‘...")
    save_video_of_best(
        best_ever_params, 
        network, 
        env_name, 
        config.GENERATIONS, 
        config.MAX_STEPS
    )
    
    env_train.close()
    
    print(f"\næ¨¡å‹å·²ä¿å­˜ä¸º: {config.BEST_MODEL_PATH}")
    print(f"è§†é¢‘å·²ä¿å­˜åˆ°: videos/ ç›®å½•")
    print(f"è®­ç»ƒç»Ÿè®¡å·²ä¿å­˜ä¸º: {config.STATS_PATH}")
    print("\nä½¿ç”¨ python visualize.py æŸ¥çœ‹è®­ç»ƒæ›²çº¿å’Œæœ€ç»ˆæ•ˆæœ")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nè®­ç»ƒè¢«ä¸­æ–­")
    except Exception as e:
        print(f"\n\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

